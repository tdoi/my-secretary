#### やったこと
- AI SDR
    - Outcome Agent の実装
        - アプローチ処理の実装
        - Reactive な処理の実装

#### やること
- AI SDR
    - Outcome Agent の実装
        - エージェントの意思決定について再考
    - Momentum Depot
        - エージェントの意思決定を UI上に反映

#### 所感
システムを作成する上で、その実現性のために、LLM を便利な道具として、モデリングしてしまっていることに気付く。

エージェントとして捉えるということは、人として捉えるということであり、極論すれば、その内部の判断について、ブラックボックス化することを許容するということであるのかもしれない。

人に依頼するかのように、必要な情報を提示した上で、どのような振る舞いが可能なのか、その振る舞いのゆらぎがどの程度なのか、そのゆらぎの範囲が許容できるのか、そして、そのゆらぎが許容できないという判断になった場合において、内部構造を指定するような制御が必要になるのが、人として信じるということなのかもしれない。

だからこそ、より人のように振る舞う可能性を引き出せるはず。

中途半端にエージェントの構造を規定することにより、その可能性を奪ってしまうかもしれないという発想は持ったことがなかった。大きな思考の転換が必要となる。

LLM が人のように判断ができると信じた上で、どんな情報を提供し、どのような観点で思考させるのかを、より人間らしく規定することが差別化につながり、そこについてどれだけ深い思考をしてきたかが勝負になるのかもしれない。
